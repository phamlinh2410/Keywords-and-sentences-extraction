{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minute-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portuguese-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statutory-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTreatment(sentences, length):\n",
    "    punctuations = []     # Dấu câu\n",
    "    with open(\"punctuation.txt\", \"r\", encoding = \"utf-8\") as data:\n",
    "        for line in data:\n",
    "            punctuations.append(line.strip())\n",
    "    data.close()\n",
    "    \n",
    "    stopWords = []\n",
    "    with open(\"vietnamese-stopwords-dash.txt\", \"r\", encoding = \"utf-8\") as data:\n",
    "        for line in data:\n",
    "            stopWords.append(line.strip())\n",
    "    data.close()\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        for j in range(0, len(sentences[i])):\n",
    "            sentences[i][j] = sentences[i][j].lower()\n",
    "        #print(sentences[i])\n",
    "        \n",
    "    # Loại bỏ dấu câu và stop words\n",
    "    for i in range(0, length):\n",
    "        sentences[i] = list(set(sentences[i]) - set(punctuations) - set(stopWords))\n",
    "        #print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impressive-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacentMatrix(sentences, length):\n",
    "    # Tạo ma trận kề của đồ thị có trọng số\n",
    "    matrix = np.zeros((length, length))\n",
    "    for i in range(0, length):\n",
    "        for j in range(0, length):\n",
    "            if i != j:\n",
    "                jaccard = len(set(sentences[i]) & set(sentences[j])) / len(set(sentences[i]) | set(sentences[j]))\n",
    "                if jaccard != 0:\n",
    "                    matrix[i][j] = jaccard\n",
    "    #for i in range(0, length):\n",
    "        #for j in range(0, length):\n",
    "            #print(matrix[i][j], end=\"\\t\")\n",
    "        #print()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respected-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textRank(matrix, length):\n",
    "    # sumOut là vector trong đó sumOut[i] là tổng trọng số của các link out của matrix[i]\n",
    "    sumOut = np.zeros(length)\n",
    "    for i in range(0, length):\n",
    "        for j in range(0, length):\n",
    "            if matrix[i][j] != 0:\n",
    "                sumOut[i] += matrix[i][j]\n",
    "    #print(sumOut)\n",
    "    \n",
    "    WS = np.ones(length)        # vector điểm của các đỉnh ở lần tính thứ n\n",
    "    preWS = np.ones(length)     # vector điểm của các đỉnh ở lần tính thứ n - 1\n",
    "    \n",
    "    d = 0.85\n",
    "    x = 0\n",
    "    \n",
    "    # Áp dụng thuật toán ranking trên đồ thị có trọng số\n",
    "    while x < 100:\n",
    "        for i in range(0, length):\n",
    "            sum = 0\n",
    "            for j in range(0, length):\n",
    "                if matrix[i][j] != 0:\n",
    "                    sum += (matrix[j][i] / sumOut[j]) * preWS[j]\n",
    "            WS[i] = (1 - d) + d * sum\n",
    "        for i in range(0, length):\n",
    "            preWS[i] = WS[i]\n",
    "        #print(\"WS lần thứ:\", x)\n",
    "        #print(WS)\n",
    "        x += 1\n",
    "    return WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expressed-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencesExtraction(WS, word_segmented_text, length):\n",
    "    # Tìm đỉnh có điểm cao nhất\n",
    "    dictWS = {}\n",
    "    for i in range(0, length):\n",
    "        dictWS[WS[i]] = i\n",
    "        \n",
    "    mainSentences = []\n",
    "    \n",
    "    for i in sorted(dictWS.keys()):\n",
    "        mainSentences.append(word_segmented_text[dictWS[i]])\n",
    "    return mainSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "representative-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    annotator = VnCoreNLP(r\"C:\\Users\\admin\\Desktop\\kit\\VnCoreNLP\\VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,parse\", max_heap_size='-Xmx2g')\n",
    "    \n",
    "    data = open(\"text.txt\", \"r\", encoding=\"utf-8\")\n",
    "    text = data.read()\n",
    "    #text = \"Ông Nguyễn Khắc Chúc đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n",
    "    \n",
    "    annotated_text = annotator.annotate(text)\n",
    "    word_segmented_text = annotator.tokenize(text)\n",
    "    \n",
    "    sentences = word_segmented_text.copy()\n",
    "    length = len(word_segmented_text)\n",
    "    \n",
    "    preTreatment(sentences, length)\n",
    "    matrix = adjacentMatrix(sentences, length)\n",
    "    WS = textRank(matrix, length)\n",
    "    mainSentences = sentencesExtraction(WS, word_segmented_text, length)\n",
    "    \n",
    "    print(mainSentences[length - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prompt-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['luật_sư', 'lê_trung_sơn', 'phân_tích', 'thêm', ',', 'khi', 'cho', 'ý_kiến', 'đồng_ý', 'với', 'nội_dung', 'tờ_trình', 'số', '835', ',', 'bị_cáo', 'hưng', 'chỉ', 'có', 'mong_muốn', 'đổi_mới', ',', 'tháo_gỡ', 'khó_khăn', 'cho', 'dự_án', '.']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-columbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
